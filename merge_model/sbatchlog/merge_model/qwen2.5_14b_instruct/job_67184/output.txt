Job started on klb-dgx-002 at Mon Jun 30 10:49:41 AM HKT 2025
SLURM_JOB_ID: 67184

=============
== PyTorch ==
=============

NVIDIA Release 25.03 (build 148941828)
PyTorch Version 2.7.0a0+7c8ec84
Container image Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

GOVERNING TERMS: The software and materials are governed by the NVIDIA Software License Agreement
(found at https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/)
and the Product-Specific Terms for NVIDIA AI Products
(found at https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/).

ERROR: This container was built for NVIDIA Driver Release 570.124 or later, but
       version 535.161.08 was detected and compatibility mode is UNAVAILABLE.

       [[]]

[2025-06-30 10:49:47,461] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/users/1786/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.

‚úÖ Successfully merged LoRA adapter into base model!
üìÅ Merged model saved to: ./merged_models/Qwen2.5-14B-Instruct
üîß Used 1 GPUs
‚úÖ Merge model completed at Mon Jun 30 10:52:46 HKT 2025
üéâ All tasks completed successfully!
==================================
Job finished at Mon Jun 30 10:52:46 AM HKT 2025
Exit code: 0
üéâ Job completed successfully!
